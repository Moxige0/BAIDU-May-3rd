{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 常规赛：论文引用节点分类-5月第三名笔记\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**本项目参考自同学的思路，原项目地址如下：[https://aistudio.baidu.com/aistudio/projectdetail/2025629](https://aistudio.baidu.com/aistudio/projectdetail/2025629)。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "整体思路:小模型（残差结构）+ Unimp => 本地投票 \n",
    "\n",
    "运行环境 ：paddle 1.8.4 python3 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "根据往期大神们的经验，使用残差结构可以提点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "训练次数达到300轮左右，趋于稳定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/81b3a9b117154b479ff76afd89f2db53edf7c5964dee4c8e846da62bfeea90c6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 残差结构模型设计 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ResGAT(object):\r\n",
    "    \"\"\"Implement of ResGAT\"\"\"\r\n",
    "    def __init__(self, config, num_class):\r\n",
    "        self.num_class = num_class \r\n",
    "        self.num_layers = config.get(\"num_layers\", 1)\r\n",
    "        self.num_heads = config.get(\"num_heads\", 8)\r\n",
    "        self.hidden_size = config.get(\"hidden_size\", 8)\r\n",
    "        self.feat_dropout = config.get(\"feat_drop\", 0.6)\r\n",
    "        self.attn_dropout = config.get(\"attn_drop\", 0.6)\r\n",
    "        self.edge_dropout = config.get(\"edge_dropout\", 0.0)\r\n",
    "\r\n",
    "    def forward(self, graph_wrapper, feature, phase):\r\n",
    "        # feature [num_nodes, 100]\r\n",
    "        if phase == \"train\": \r\n",
    "            edge_dropout = self.edge_dropout\r\n",
    "        else:\r\n",
    "            edge_dropout = 0\r\n",
    "        feature = L.fc(feature, size=self.hidden_size * self.num_heads, name=\"init_feature\")\r\n",
    "        for i in range(self.num_layers):\r\n",
    "            ngw = pgl.sample.edge_drop(graph_wrapper, edge_dropout) \r\n",
    "            \r\n",
    "            res_feature = feature\r\n",
    "            # res_feature [num_nodes, hidden_size * n_heads]\r\n",
    "            feature = conv.gat(ngw,\r\n",
    "                                feature,\r\n",
    "                                self.hidden_size,\r\n",
    "                                activation=None,\r\n",
    "                                name=\"gat_layer_%s\" % i,\r\n",
    "                                num_heads=self.num_heads,\r\n",
    "                                feat_drop=self.feat_dropout,\r\n",
    "                                attn_drop=self.attn_dropout)\r\n",
    "            # feature [num_nodes, num_heads * hidden_size]\r\n",
    "            feature = res_feature + feature \r\n",
    "            # [num_nodes, num_heads * hidden_size] + [ num_nodes, hidden_size * n_heads]\r\n",
    "            feature = L.relu(feature)\r\n",
    "            feature = L.layer_norm(feature, name=\"ln_%s\" % i)\r\n",
    "\r\n",
    "        ngw = pgl.sample.edge_drop(graph_wrapper, edge_dropout) \r\n",
    "        feature = conv.gat(ngw,\r\n",
    "                     feature,\r\n",
    "                     self.num_class,\r\n",
    "                     num_heads=1,\r\n",
    "                     activation=None,\r\n",
    "                     feat_drop=self.feat_dropout,\r\n",
    "                     attn_drop=self.attn_dropout,\r\n",
    "                     name=\"output\")\r\n",
    "        return feature\r\n",
    "\r\n",
    "\r\n",
    "class ResGCN(object):\r\n",
    "    \"\"\"Implement of GCN\r\n",
    "    \"\"\"\r\n",
    "    def __init__(self, config, num_class):\r\n",
    "        self.num_class = num_class\r\n",
    "        self.num_layers = config.get(\"num_layers\", 1)\r\n",
    "        self.hidden_size = config.get(\"hidden_size\", 64)\r\n",
    "        self.dropout = config.get(\"dropout\", 0.5)\r\n",
    "        self.edge_dropout = config.get(\"edge_dropout\", 0.0)\r\n",
    "\r\n",
    "    def forward(self, graph_wrapper, feature, phase):\r\n",
    "        \r\n",
    "        for i in range(self.num_layers):\r\n",
    "            \r\n",
    "            if phase == \"train\":\r\n",
    "                ngw = pgl.sample.edge_drop(graph_wrapper, self.edge_dropout) \r\n",
    "                norm = get_norm(ngw.indegree())\r\n",
    "            else:\r\n",
    "                ngw = graph_wrapper\r\n",
    "                norm = graph_wrapper.node_feat[\"norm\"]\r\n",
    "\r\n",
    "            res_feature = L.fc(feature, size=self.hidden_size, name=\"res_feature\")\r\n",
    "            \r\n",
    "            feature = pgl.layers.gcn(ngw,\r\n",
    "                feature,\r\n",
    "                self.hidden_size,\r\n",
    "                activation=\"relu\",\r\n",
    "                norm=norm,\r\n",
    "                name=\"layer_%s\" % i)\r\n",
    "\r\n",
    "            feature = res_feature + feature \r\n",
    "\r\n",
    "            feature = L.dropout(\r\n",
    "                    feature,\r\n",
    "                    self.dropout,\r\n",
    "                    dropout_implementation='upscale_in_train')\r\n",
    "\r\n",
    "        if phase == \"train\": \r\n",
    "            ngw = pgl.sample.edge_drop(graph_wrapper, self.edge_dropout) \r\n",
    "            norm = get_norm(ngw.indegree())\r\n",
    "        else:\r\n",
    "            ngw = graph_wrapper\r\n",
    "            norm = graph_wrapper.node_feat[\"norm\"]\r\n",
    "\r\n",
    "        feature = conv.gcn(ngw,\r\n",
    "                     feature,\r\n",
    "                     self.num_class,\r\n",
    "                     activation=None,\r\n",
    "                     norm=norm,\r\n",
    "                     name=\"output\")\r\n",
    "\r\n",
    "        return feature\r\n",
    "\r\n",
    "        feature = L.fc(feature, self.num_class, act=None, name=\"output\")\r\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 保存输出，进行投票"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "这里将训练出来的文件进行简单投票\n",
    "```\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def vote_merge(filelst):\n",
    "    result = {}\n",
    "    fw = open('D:/subexl/76/merge.csv', encoding='utf-8', mode='w', newline='')\n",
    "    csv_writer = csv.writer(fw)\n",
    "    csv_writer.writerow(['nid', 'label'])\n",
    "    for filepath in filelst:\n",
    "        cr = open(filepath, encoding='utf-8', mode='r')\n",
    "        csv_reader = csv.reader(cr)\n",
    "        for i, row in enumerate(csv_reader):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            idx, cls = row\n",
    "            if idx not in result:\n",
    "                result[idx] = []\n",
    "            result[idx].append(cls)\n",
    "\n",
    "    for nid, clss in result.items():\n",
    "        counter = Counter(clss)\n",
    "        true_cls = counter.most_common(1)\n",
    "        csv_writer.writerow([nid, true_cls[0][0]])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    vote_merge([\n",
    "        \"D:/subexl/76/0.75736.csv\",\n",
    "        \"D:/subexl/76/0.75755.csv\",\n",
    "        \"D:/subexl/76/0.75801.csv\",\n",
    "        \"D:/subexl/76/0.75868.csv\",\n",
    "        \"D:/subexl/76/0.75978.csv\",\n",
    "        \"D:/subexl/76/0.76436.csv\",\n",
    "        \"D:/subexl/76/0.759664.csv\",\n",
    "        \"D:/subexl/76/0.75973517.csv\",\n",
    "        \"D:/subexl/76/0.75980633.csv\",\n",
    "        \"D:/subexl/76/0.76322347.csv\",\n",
    "        \"D:/subexl/76/0.763223471.csv\",\n",
    "        \"D:/subexl/76/submission.csv\",\n",
    "                ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# UniMP：统一消息传递模型\n",
    "\n",
    "在半监督图节点分类场景下，节点之间通过边相连接，部分节点被打上标签。任务要求模型通过监督学习的方式，拟合被标注节点数据，并对未标注的节点进行预测。如下图所示，在一般机器学习的问题上，已标注的训练数据在新数据的推断上，并不能发挥直接的作用，因为数据的输入是独立的。然而在图神经网络的场景下，已有的标注数据可以从节点与节点的连接中，根据图结构关系推广到新的未标注数据中。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/7fca182598e44fcba9c10e8713672a21f7964f8ffac54e688b6e6842de76970a)\n",
    "\n",
    "\n",
    "\n",
    "一般应用于半监督节点分类的算法分为图神经网络和标签传递算法两类，它们都是通过消息传递的方式(前者传递特征、后者传递标签)进行节点标签的学习和预测。其中经典标签传递算法如LPA，只考虑了将标签在图上进行传递，而图神经网络算法大多也只是使用了节点特征以及图的链接信息进行分类。但是单纯考虑标签传递或者节点特征都是不足够的。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/04ca472bda354322a1f36416dbf98866a5e702b489ba4abaa3ad0debbae76a90)\n",
    "\n",
    "\n",
    "百度PGL团队提出的统一消息传递模型 UniMP，将上述两种消息统一到框架中，同时实现了节点的特征与标签传递，显著提升了模型的泛化效果。 UniMP以Graph Transformer模型作为基础骨架，联合使用标签嵌入方法，将节点特征和部分节点标签同时输入至模型中，从而实现了节点特征和标签的同时传递。\n",
    "\n",
    "简单的加入标签信息会带来标签泄漏的问题，即标签信息即是特征又是训练目标。实际上，标签大部分是有顺序的，例如在引用网络中，论文是按照时间先后顺序出现的，其标签也应该有一定的先后顺序。在无法得知训练集标签顺序的情况下，UniMP提出了标签掩码学习方法。UniMP每一次随机将一定量的节点标签掩码为未知，用部分已有的标注信息、图结构信息以及节点特征来还原训练数据的标签。最终，UniMP在OGB上取得SOTA效果，并在论文的消融实验上，验证了方法的有效性。\n",
    "\n",
    "使用该模型结构，结合残差网络，加上调整好参数，集成模型即可取得top1的分数."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# unimp代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```\n",
    "class UniMP(object):\n",
    "    def __init__(self, config, num_class):\n",
    "        self.num_class = num_class\n",
    "        self.num_layers = config.get(\"num_layers\", 2)\n",
    "        self.hidden_size = config.get(\"hidden_size\", 64)\n",
    "        self.out_size=config.get(\"out_size\", 40)\n",
    "        self.embed_size=config.get(\"embed_size\", 100)\n",
    "        self.heads = config.get(\"heads\", 8) \n",
    "        self.dropout = config.get(\"dropout\", 0.3)\n",
    "        self.edge_dropout = config.get(\"edge_dropout\", 0.0)\n",
    "        self.use_label_e = config.get(\"use_label_e\", False)\n",
    "            \n",
    "    \n",
    "    def embed_input(self, feature):\n",
    "        \n",
    "        lay_norm_attr=F.ParamAttr(initializer=F.initializer.ConstantInitializer(value=1))\n",
    "        lay_norm_bias=F.ParamAttr(initializer=F.initializer.ConstantInitializer(value=0))\n",
    "        feature=L.layer_norm(feature, name='layer_norm_feature_input', \n",
    "                                      param_attr=lay_norm_attr, \n",
    "                                      bias_attr=lay_norm_bias)\n",
    "        \n",
    "        return feature\n",
    "\n",
    "    def label_embed_input(self, feature):\n",
    "        label = F.data(name=\"label\", shape=[None, 1], dtype=\"int64\")\n",
    "        label_idx = F.data(name='label_idx', shape=[None, 1], dtype=\"int64\")\n",
    "\n",
    "        label = L.reshape(label, shape=[-1])\n",
    "        label_idx = L.reshape(label_idx, shape=[-1])\n",
    "\n",
    "        embed_attr = F.ParamAttr(initializer=F.initializer.NormalInitializer(loc=0.0, scale=1.0))\n",
    "        embed = F.embedding(input=label, size=(self.out_size, self.embed_size), param_attr=embed_attr )\n",
    "\n",
    "        feature_label = L.gather(feature, label_idx, overwrite=False)\n",
    "        feature_label = feature_label + embed\n",
    "        feature = L.scatter(feature, label_idx, feature_label, overwrite=True)\n",
    "\n",
    "        \n",
    "        lay_norm_attr = F.ParamAttr(initializer=F.initializer.ConstantInitializer(value=1))\n",
    "        lay_norm_bias = F.ParamAttr(initializer=F.initializer.ConstantInitializer(value=0))\n",
    "        feature = L.layer_norm(feature, name='layer_norm_feature_input', \n",
    "                                      param_attr=lay_norm_attr, \n",
    "                                      bias_attr=lay_norm_bias)\n",
    "        return feature\n",
    "    \n",
    "    def get_gat_layer(self, i, gw, feature, hidden_size, num_heads, concat=True,\n",
    "                      layer_norm=True, relu=True, gate=False):\n",
    "        fan_in=feature.shape[-1]\n",
    "        bias_bound = 1.0 / math.sqrt(fan_in)\n",
    "        fc_bias_attr = F.ParamAttr(initializer=F.initializer.UniformInitializer(low=-bias_bound, high=bias_bound))\n",
    "        \n",
    "        negative_slope = math.sqrt(5)\n",
    "        gain = math.sqrt(2.0 / (1 + negative_slope ** 2))\n",
    "        std = gain / math.sqrt(fan_in)\n",
    "        weight_bound = math.sqrt(3.0) * std\n",
    "        fc_w_attr = F.ParamAttr(initializer=F.initializer.UniformInitializer(low=-weight_bound, high=weight_bound))\n",
    "        \n",
    "        if concat:\n",
    "            skip_feature = L.fc(feature,\n",
    "                         hidden_size * num_heads,\n",
    "                           param_attr=fc_w_attr,\n",
    "                           name='fc_skip_' + str(i),\n",
    "                           bias_attr=fc_bias_attr)\n",
    "        else:\n",
    "            skip_feature = L.fc(feature,\n",
    "                         hidden_size,\n",
    "                           param_attr=fc_w_attr,\n",
    "                           name='fc_skip_' + str(i),\n",
    "                           bias_attr=fc_bias_attr)\n",
    "        out_feat = transformer_gat_pgl(gw, feature, hidden_size, 'gat_' + str(i), num_heads, concat=concat) \n",
    "        # out_feat= out_feat + skip_feature\n",
    "        \n",
    "        if gate: \n",
    "            fan_in = out_feat.shape[-1]*3\n",
    "            bias_bound = 1.0 / math.sqrt(fan_in)\n",
    "            fc_bias_attr = F.ParamAttr(initializer=F.initializer.UniformInitializer(low=-bias_bound, high=bias_bound))\n",
    "\n",
    "            negative_slope = math.sqrt(5)\n",
    "            gain = math.sqrt(2.0 / (1 + negative_slope ** 2))\n",
    "            std = gain / math.sqrt(fan_in)\n",
    "            weight_bound = math.sqrt(3.0) * std\n",
    "            fc_w_attr = F.ParamAttr(initializer=F.initializer.UniformInitializer(low=-weight_bound, high=weight_bound))\n",
    "            gate_f = L.fc([skip_feature, out_feat, out_feat - skip_feature], 1,\n",
    "                           param_attr=fc_w_attr,\n",
    "                           name='gate_' + str(i),\n",
    "                           bias_attr=fc_bias_attr)\n",
    "            \n",
    "            gate_f = L.sigmoid(gate_f) \n",
    "            out_feat = skip_feature * gate_f + out_feat * (1 - gate_f)\n",
    "        else:\n",
    "            out_feat = out_feat + skip_feature\n",
    "                 \n",
    "        if layer_norm:\n",
    "            lay_norm_attr = F.ParamAttr(initializer=F.initializer.ConstantInitializer(value=1))\n",
    "            lay_norm_bias = F.ParamAttr(initializer=F.initializer.ConstantInitializer(value=0))\n",
    "            out_feat = L.layer_norm(out_feat, name='layer_norm_' + str(i), \n",
    "                                      param_attr=lay_norm_attr, \n",
    "                                      bias_attr=lay_norm_bias)\n",
    "        if relu:\n",
    "            out_feat = L.relu(out_feat)\n",
    "        return out_feat\n",
    "        \n",
    "    def forward(self, graph_wrapper, feature, phase):\n",
    "        if phase == \"train\": \n",
    "            edge_dropout = self.edge_dropout\n",
    "            dropout = self.dropout\n",
    "        else:\n",
    "            edge_dropout = 0\n",
    "            dropout = 0\n",
    "\n",
    "        if self.use_label_e:\n",
    "            feature = self.label_embed_input(feature)\n",
    "            gate = True\n",
    "        else:\n",
    "            feature = self.embed_input(feature)\n",
    "            gate = False\n",
    "        if dropout > 0:\n",
    "            feature = L.dropout(feature, dropout_prob=dropout, \n",
    "                                    dropout_implementation='upscale_in_train')\n",
    "        for i in range(self.num_layers - 1):\n",
    "            ngw = pgl.sample.edge_drop(graph_wrapper, edge_dropout) \n",
    "            feature = self.get_gat_layer(i, ngw, feature, \n",
    "                                             hidden_size=self.hidden_size,\n",
    "                                             num_heads=self.heads, \n",
    "                                             concat=True, \n",
    "                                             layer_norm=True, relu=True, gate=gate)\n",
    "            if dropout > 0:\n",
    "                feature = L.dropout(feature, dropout_prob=self.dropout, \n",
    "                                     dropout_implementation='upscale_in_train') \n",
    "\n",
    "        feature = self.get_gat_layer(self.num_layers - 1, ngw, feature, \n",
    "                                           hidden_size=self.out_size, num_heads=self.heads, \n",
    "                                             concat=False, layer_norm=False, relu=False, gate=True)\n",
    "  \n",
    "        pred = L.fc(\n",
    "            feature, self.num_class, act=None, name=\"pred_output\")\n",
    "        return pred\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 运行方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting python-dateutil\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 16.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from python-dateutil) (1.15.0)\n",
      "\u001b[31mERROR: blackhole 0.3.2 has requirement xgboost==1.1.0, but you'll have xgboost 1.3.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: python-dateutil\n",
      "  Found existing installation: python-dateutil 2.8.0\n",
      "    Uninstalling python-dateutil-2.8.0:\n",
      "      Successfully uninstalled python-dateutil-2.8.0\n",
      "Successfully installed python-dateutil-2.8.1\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: easydict in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (1.9)\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting pgl==1.2.0\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/35/fa/2290e78914d34d4e4480d7982b8f4d0c58a7e53535113a668a9d75d5c3b6/pgl-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (7.9MB)\n",
      "\u001b[K     |████████████████████████████████| 7.9MB 18.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl==1.2.0) (1.16.4)\n",
      "Requirement already satisfied: visualdl>=2.0.0b; python_version >= \"3\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl==1.2.0) (2.1.1)\n",
      "Requirement already satisfied: cython>=0.25.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pgl==1.2.0) (0.29)\n",
      "Collecting redis-py-cluster (from pgl==1.2.0)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/b2/96/153bbcf5dee29b52b2674e77a87ce864d381f72151737317529b7de4f337/redis_py_cluster-2.1.3-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 29.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.15.0)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.7.1.1)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.8.53)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (3.8.2)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.0.0)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.21.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.22.0)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (3.14.0)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.1.1)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (7.1.2)\n",
      "Collecting redis<4.0.0,>=3.0.0 (from redis-py-cluster->pgl==1.2.0)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/a7/7c/24fb0511df653cf1a5d938d8f5d19802a88cef255706fdda242ff97e91b7/redis-3.5.3-py2.py3-none-any.whl (72kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 58.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.18.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (3.9.9)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.2.0)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.6.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.6.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.23)\n",
      "Requirement already satisfied: Jinja2>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.10.3)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2019.3)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (16.7.9)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.3.4)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.3.0)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.10.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.0.1)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.4.10)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (5.1.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.25.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (2019.9.11)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.16.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.5->Flask-Babel>=1.0.0->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (1.1.1)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl>=2.0.0b; python_version >= \"3\"->pgl==1.2.0) (7.2.0)\n",
      "Installing collected packages: redis, redis-py-cluster, pgl\n",
      "Successfully installed pgl-1.2.0 redis-3.5.3 redis-py-cluster-2.1.3\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Collecting pyarrow==0.13.0\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/3f/6c/91a3d949fe0763e60ac181b7b79e74e848e33e402e5e8274cad455519d76/pyarrow-0.13.0-cp37-cp37m-manylinux1_x86_64.whl (48.5MB)\n",
      "\u001b[K     |████████████████████████████████| 48.5MB 8.3MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pyarrow==0.13.0) (1.16.4)\n",
      "Requirement already satisfied: six>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pyarrow==0.13.0) (1.15.0)\n",
      "\u001b[31mERROR: blackhole 0.3.2 has requirement pyarrow>=0.14.1, but you'll have pyarrow 0.13.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: blackhole 0.3.2 has requirement xgboost==1.1.0, but you'll have xgboost 1.3.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pyarrow\n",
      "  Found existing installation: pyarrow 2.0.0\n",
      "    Uninstalling pyarrow-2.0.0:\n",
      "      Successfully uninstalled pyarrow-2.0.0\n",
      "Successfully installed pyarrow-0.13.0\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/\n",
      "Requirement already satisfied: chardet==3.0.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (3.0.4)\n",
      "E0604 17:09:12.021716   538 pybind.cc:1277] Cannot use GPU because you have installed CPU version PaddlePaddle.\n",
      "If you want to use GPU, please try to install GPU version PaddlePaddle by: pip install paddlepaddle-gpu\n",
      "If you only have CPU, please change CUDAPlace(0) to be CPUPlace().\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade python-dateutil\r\n",
    "!pip install easydict\r\n",
    "!pip install pgl==1.2.0 \r\n",
    "!pip install pandas>=0.25\r\n",
    "!pip install pyarrow==0.13.0\r\n",
    "!pip install chardet==3.0.4\r\n",
    "!python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.4 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
